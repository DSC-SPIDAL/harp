<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>harp</title>
    <link>https://dsc-spidal.github.io/harp/index.xml</link>
    <description>Recent content on harp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://dsc-spidal.github.io/harp/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title></title>
      <link>https://dsc-spidal.github.io/harp/docs/applications/dataset-lda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/applications/dataset-lda/</guid>
      <description>

&lt;h1 id=&#34;datasets-for-lda&#34;&gt;datasets for lda&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;nytimes,pubmed:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;standard text dataset in the UCI repository.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://archive.ics.uci.edu/ml/datasets/bag+of+words&#34;&gt;https://archive.ics.uci.edu/ml/datasets/bag+of+words&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;enwiki,bigram:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Articles in English in the 18-May-2015 dump.
First, download the dump of all Wikipedia articles from &lt;a href=&#34;http://download.wikimedia.org/enwiki/&#34;&gt;http://download.wikimedia.org/enwiki/&lt;/a&gt; (you want a file like enwiki-latest-pages-articles.xml.bz2). This file is about 8GB in size and contains (a compressed version of) all articles from the English Wikipedia.&lt;/p&gt;

&lt;p&gt;Preprocess the wikipedia documents by gensim toolkits, and calculate the tf-idf value for each documen-word pair and create this dataset useable for mf problems.&lt;/p&gt;

&lt;p&gt;Bigram version as bigram.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;clueweb&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://lemurproject.org/clueweb09.php/&#34;&gt;http://lemurproject.org/clueweb09.php/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://boston.lti.cs.cmu.edu/clueweb09/wiki/tiki-index.php?page=Dataset+Information&#34;&gt;http://boston.lti.cs.cmu.edu/clueweb09/wiki/tiki-index.php?page=Dataset+Information&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The ClueWeb09 dataset was created to support research on information retrieval and related human language technologies. It consists of about 1 billion web pages in ten languages that were collected in January and February 2009. The dataset is used by several tracks of the TREC conference.&lt;/p&gt;

&lt;p&gt;We select sbuset of english webpages from the collection, and preprocess to convert it into a tf-idf document-word matrix.
There are different versions, one is clueweb10b with 10b training examples, the other one is clueweb30b.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dsc-spidal.github.io/harp/docs/harpdaal/handson/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/harpdaal/handson/</guid>
      <description>

&lt;h1 id=&#34;choose-the-right-ml-tool-and-use-it-like-a-pro&#34;&gt;Choose the right ML tool and use it like a pro!&lt;/h1&gt;

&lt;p&gt;K-means is a widely used clustering algorithm in machine learning community.
It iteratively computes the distance between each training point to every centroid,
re-assigns the training point to new cluster and re-compute the new centroid of each cluster.&lt;/p&gt;

&lt;p&gt;This hands-on includes two tasks&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write a Harp-DAAL K-means program by using Java API (8 steps)&lt;/li&gt;
&lt;li&gt;Run and tune Harp-DAAL K-means from an image clustering application via python API (5 steps)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Users are supposed to get an access to a machine with sudo permission and pre-installed docker environment.&lt;/p&gt;

&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;

&lt;h3 id=&#34;download-docker-image-and-launch-container-instance&#34;&gt;Download Docker Image and launch Container Instance&lt;/h3&gt;

&lt;p&gt;Execute the two commands to load docker image and launch a container instance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# Download an image&lt;/span&gt;
sudo docker pull lee212/harp-daal:icc_included
&lt;span style=&#34;color: #75715e&#34;&gt;# Start a container&lt;/span&gt;
sudo docker run -it lee212/harp-daal:icc_included /etc/bootstrap.sh -bash
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After executing the last command you will be logged on to the docker image.&lt;/p&gt;

&lt;p&gt;The container takes up to 20GB disk space. If the machine has more than 50GB disk space, there shall be no problem to
launch the container instance. Otherwise, users could use the following commands to clean up the docker space&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# Remove useless docker images&lt;/span&gt;
sudo docker image rm &amp;lt;useless-docker-image&amp;gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# Remove exited containers&lt;/span&gt;
sudo docker rm &lt;span style=&#34;color: #66d9ef&#34;&gt;$(&lt;/span&gt;sudo docker ps -a -f &lt;span style=&#34;color: #f8f8f2&#34;&gt;status&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;exited -q&lt;span style=&#34;color: #66d9ef&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# Clean up all dangling cache&lt;/span&gt;
sudo docker system prune
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Find the docker container ID&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;sudo docker ps
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and log into the docker&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;sudo docker &lt;span style=&#34;color: #f8f8f2&#34;&gt;exec&lt;/span&gt; -it &amp;lt;container_id&amp;gt; bash
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If network is not available, a docker image in tar file is provided with the instructions to load.
&lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/load/&#34;&gt;https://docs.docker.com/engine/reference/commandline/load/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;dependencies-and-environment-variables&#34;&gt;Dependencies and Environment Variables&lt;/h3&gt;

&lt;p&gt;The hands-on codes have the dependencies as follows,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Python 2.7+&lt;/li&gt;
&lt;li&gt;Python module Numpy&lt;/li&gt;
&lt;li&gt;Hadoop 2.6.0/Hadoop 2.6.5&lt;/li&gt;
&lt;li&gt;DAAL 2018+&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following section describes where the important components of the Tutorial are&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Harp Source Code - /harp&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Hadoop Installation - /usr/local/hadoop&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;K-Means tutorial code - /harp/harp-daal-app/src/main/java/edu/iu/daal_tutorial/daal_kmeans&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Python Code - /harp/harp-daal-python/examples/daal/&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The docker image already includes them and other tools, the image has the following machine learning algorithms&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# List of HarpDaal applications (in harp-daal-&amp;lt;version&amp;gt;.jar)&lt;/span&gt;
edu.iu.daal_als.ALSDaalLauncher
edu.iu.daal_cov.COVDaalLauncher
edu.iu.daal_kmeans.regroupallgather.KMeansDaalLauncher
edu.iu.daal_linreg.LinRegDaalLauncher
edu.iu.daal_mom.MOMDaalLauncher
edu.iu.daal_naive.NaiveDaalLauncher
edu.iu.daal_nn.NNDaalLauncher
edu.iu.daal_pca.PCADaalLauncher
edu.iu.daal_qr.QRDaalLauncher
edu.iu.daal_ridgereg.RidgeRegDaalLauncher
edu.iu.daal_sgd.SGDDaalLauncher
edu.iu.daal_svd.SVDDaalLauncher

&lt;span style=&#34;color: #75715e&#34;&gt;# List of HarpDaal examples in Python (/harp/harp-daal-python/examples/daal/)&lt;/span&gt;
run_harp_daal_ALSDaal.py
run_harp_daal_COVDaal.py
run_harp_daal_KMeansDaal.py
run_harp_daal_LinRegDaal.py
run_harp_daal_MOMDaal.py
run_harp_daal_NNDaal.py
run_harp_daal_NaiveDaal.py
run_harp_daal_PCADaal.py
run_harp_daal_QRDaal.py
run_harp_daal_RidgeRegDaal.py
run_harp_daal_SGDDaal.py
run_harp_daal_SVDDaal.py

&lt;span style=&#34;color: #75715e&#34;&gt;# Image clustering example&lt;/span&gt;
/harp/harp-daal-python/examples/scdemo/tutorial/
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The &lt;em&gt;bootstrap&lt;/em&gt; script shall launch a Hadoop Cluster and set up all the environment variables.
To verify the Hadoop status&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;## To check the status of HDFS&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/bin/hdfs dfsadmin -report
&lt;span style=&#34;color: #75715e&#34;&gt;## To check the status of Yarn &lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/bin/yarn node -list
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Check out the environment variables to figure out the locations of the important files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;$HADOOP_HOME&lt;/span&gt;
/usr/local/hadoop

&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;$HARP_JAR&lt;/span&gt;
/usr/local/hadoop/harp-app-0.1.0.jar

&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;$HARP_DAAL_JAR&lt;/span&gt;
/usr/local/hadoop/harp-daal-app-0.1.0.jar

&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;$DAALROOT&lt;/span&gt;
/harp/harp-daal-app/__release__lnx/daal

&lt;span style=&#34;color: #f8f8f2&#34;&gt;echo&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;$PYTHONPATH&lt;/span&gt;
/harp/harp-daal-python
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If the script fails to complete these steps, users could manually set them&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&amp;lt;path to hadoop home folder&amp;gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;HARP_JAR&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&amp;lt;path to&amp;gt;/harp-app-0.1.0.jar
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;HARP_DAAL_JAR&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&amp;lt;path to&amp;gt;/harp-daal-app-0.1.0.jar
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DAALROOT&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&amp;lt;path to your compiled daal folder&amp;gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;export&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;PYTHONPATH&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&amp;lt;path to&amp;gt;/harp-daal-python
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In a situation where you would like to stop and restart Hadoop, use the following commands&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;## stop all services&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/sbin/stop-all.sh
&lt;span style=&#34;color: #75715e&#34;&gt;## launch HDFS service&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/sbin/start-dfs.sh
&lt;span style=&#34;color: #75715e&#34;&gt;## launch yarn daemons&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;HADOOP_HOME&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/sbin/start-yarn.sh
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;program-k-means-via-java-apis&#34;&gt;Program K-means via Java APIs&lt;/h2&gt;

&lt;p&gt;Harp-DAAL framework provides developers of Java API to implement inter-mapper communication patterns and invoke intra-node DAAL kernels. The K-means source files are located at&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;/harp/harp-daal-app/src/main/java/edu/iu/daal_tutorial/daal_kmeans/
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Lets open the source file where K-Means is implemented.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;vi /harp/harp-daal-app/src/main/java/edu/iu/daal_tutorial/daal_kmeans/KMeansDaalCollectiveMapper.java
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Users shall edit the function &lt;em&gt;runKmeans&lt;/em&gt; from source file &lt;em&gt;KMeansDaalCollectiveMapper.java&lt;/em&gt;.
Currently, the function &lt;em&gt;runKmeans&lt;/em&gt; is only a skeleton, and users will go through 8 steps to finish
a complete Harp-DAAL-Kmeans application as indicated in the following code snippet.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;runKmeans&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;List&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;fileNames&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Configuration&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;conf&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Context&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color: #66d9ef&#34;&gt;long&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;start_execution&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;System&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;currentTimeMillis&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
  &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;fileNames&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;fileNames&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
  &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;conf&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;conf&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;

  &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 1: load training data *********************&lt;/span&gt;
  &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 2: load centroids (model) data *********************&lt;/span&gt;
  &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 3: convert training data from harp to daal *********************&lt;/span&gt;
  &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 4: Setup DAAL K-means kernel and cenTable at DAAL side *********************&lt;/span&gt;
  &lt;span style=&#34;color: #75715e&#34;&gt;// start the iteration&lt;/span&gt;
  &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numIterations&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 5: Convert Centroids data from Harp to DAAL *********************&lt;/span&gt;
    &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 6: Local computation by DAAL to get partial result *********************&lt;/span&gt;
    &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 7: Inter-Mapper communication *********************&lt;/span&gt;
  &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
  &lt;span style=&#34;color: #75715e&#34;&gt;//************* Step 8: Release Memory and Store Centroids *********************&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The codes of missing steps are already packaged into private member function of &lt;em&gt;KMeansDaalCollectiveMapper.java&lt;/em&gt; named &lt;em&gt;runKmeans_Answer&lt;/em&gt; and you can use it to get it to working quickly. Please refer to member function definition for
implementation details of each step. After adding codes at each step, re-compile the harp-daal-application
by maven at the root harp directory (where the pom.xml resides)&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cd&lt;/span&gt; /harp
mvn clean package
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;and re-run the application on Hadoop cluster&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cd&lt;/span&gt; /harp/harp-daal-app/test_scripts
./harp-daal-tutorial-kmeans.sh
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;solution-description&#34;&gt;Solution Description&lt;/h3&gt;

&lt;p&gt;The following sections describe each step of the algorithm that is left blank.&lt;/p&gt;

&lt;h3 id=&#34;step-1-load-training-data-feature-vectors&#34;&gt;Step 1: Load training data (feature vectors)&lt;/h3&gt;

&lt;p&gt;Use the following function to load training data from HDFS.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// create a pointArray&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;List&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;double&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pointArrays&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;LoadTrainingData&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-2-load-model-data-centroids&#34;&gt;Step 2: Load model data (centroids)&lt;/h3&gt;

&lt;p&gt;Similarly, create a harp table object &lt;em&gt;cenTable&lt;/em&gt; and load centroids from HDFS.
Because centroids are requested by all the mappers, load them at master mapper and
broadcast them to all the other mappers.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// create a table to hold centroids data&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArrPlus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;

&lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;isMaster&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;())&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2&#34;&gt;createCenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
  &lt;span style=&#34;color: #f8f8f2&#34;&gt;loadCentroids&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;// Bcast centroids to other mappers&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;bcastCentroids&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getMasterID&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-3-convert-training-data-from-harp-side-to-daal-side&#34;&gt;Step 3: Convert training data from Harp side to DAAL side&lt;/h3&gt;

&lt;p&gt;The training data loaded from HDFS are stored at Java heap memory. To invoke DAAL kernel, convert them to
DAAL &lt;em&gt;NumericTable&lt;/em&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// convert training data fro harp to daal&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;NumericTable&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;trainingdata_daal&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;convertTrainData&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;pointArrays&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It allocates native memory for &lt;em&gt;NumericTable&lt;/em&gt; and copy data from &lt;em&gt;pointArrays&lt;/em&gt; to &lt;em&gt;trainingdata_daal&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;step-4-create-and-set-up-daal-k-means-kernel&#34;&gt;Step 4: Create and set up DAAL K-means kernel&lt;/h3&gt;

&lt;p&gt;DAAL provides the following Java API to invoke their low-level native kernels written for K-means&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;com.intel.daal.algorithms.kmeans.*&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;com.intel.daal.algorithms.kmeans.init.*&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;com.intel.daal.services.Environment&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Call them by specifying the input training data object and number of centroids&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// create a daal kmeans kernel object&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;DistributedStep1Local&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;kmeansLocal&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DistributedStep1Local&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;daal_Context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Double&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;class&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Method&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;defaultDense&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;numCentroids&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;// set up input training data&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;kmeansLocal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;set&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;InputId&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;trainingdata_daal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;As DAAL uses MKL and TBB within its implementation, specify the number of threads used by DAAL (by default a maximum available threads on a processor)&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// specify the threads used in DAAL kernel&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;Environment&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;setNumberOfThreads&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;numThreads&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Finally, create another &lt;em&gt;NumericTable&lt;/em&gt; to store centroids at DAAL side&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// create cenTable at daal side&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;NumericTable&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable_daal&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;createCenTableDAAL&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-5-convert-centroids-from-harp-to-daal&#34;&gt;Step 5: Convert centroids from Harp to DAAL&lt;/h3&gt;

&lt;p&gt;Centroids are stored in harp table &lt;em&gt;cenTable&lt;/em&gt; for inter-mapper communication. Convert them
to DAAL within each iteration of local computation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;//Convert Centroids data from Harp to DAAL&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;convertCenTableHarpToDAAL&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable_daal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-6-local-computation-by-daal-kernel&#34;&gt;Step 6: Local computation by DAAL kernel&lt;/h3&gt;

&lt;p&gt;Call DAAL K-means kernels of local computation at each iteration.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// specify centroids data to daal kernel &lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;kmeansLocal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;input&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;set&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;InputId&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;inputCentroids&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable_daal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;// first step of local computation by using DAAL kernels to get partial result&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;PartialResult&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pres&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;kmeansLocal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;compute&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-7-inter-mapper-communication&#34;&gt;Step 7: Inter-mapper communication&lt;/h3&gt;

&lt;p&gt;Harp-DAAL-Kmeans adopts an &lt;em&gt;allreduce&lt;/em&gt; computation model, where each mapper keeps a local copy of the whole model data (centroids).
However, it provides different communication operations to synchronize model data among mappers.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Regroup &amp;amp; Allgather (default)&lt;/li&gt;
&lt;li&gt;Allreduce&lt;/li&gt;
&lt;li&gt;Broadcast &amp;amp; Reduce&lt;/li&gt;
&lt;li&gt;Push-Pull&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of the operations will take in two arguments, 1) &lt;em&gt;cenTable&lt;/em&gt; at harp side, 2) partial results obtained from DAAL; Internally, the data is retrieved from DAAL partial results and communicated by Harp.&lt;/p&gt;

&lt;p&gt;In Regroup &amp;amp; Allgather operation, it first combines the same centroid from different mappers and re-distributes them
to mappers by a specified order. After averaging the centroids, an allgather operation makes every mapper get
a complete copy of the averaged centroids.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;comm_regroup_allgather&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pres&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In Allreduce operation, the centroids are reduced and copied to every mapper. Then an average operation applies to them on each mapper.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;comm_allreduce&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pres&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In Broadcast &amp;amp; Reduce, it first reduces centroids to a single mapper (master mapper), where the average operation applies. It then broadcasts the averaged centroids data to every other mapper.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;comm_broadcastreduce&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pres&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In push-pull, it first pushes centroids data from &lt;em&gt;cenTable&lt;/em&gt; of local mapper to a &lt;em&gt;globalTable&lt;/em&gt;, which is distributed across all the mappers. It then applies the average operation on &lt;em&gt;globalTable&lt;/em&gt; from each mapper, and finally, pull the results from &lt;em&gt;globalTable&lt;/em&gt; to update the local &lt;em&gt;cenTable&lt;/em&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;globalTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArrPlus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;comm_push_pull&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;globalTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;pres&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After finishing each iteration, call the &lt;em&gt;printTable&lt;/em&gt; to check the centroids result&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;//for iteration i, check 10 first centroids, each &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;//centroid prints out first 10 dimension&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;printTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-8-release-memory-and-store-centroids&#34;&gt;Step 8: Release memory and store centroids&lt;/h3&gt;

&lt;p&gt;After all of the iterations, release the allocated memory at DAAL side and for harp table object.
The centroids as output are stored at HDFS&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// free memory and record time&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable_daal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;freeDataMemory&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;trainingdata_daal&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;freeDataMemory&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;// Write out centroids&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;isMaster&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;())&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;KMUtil&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;storeCentroids&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;conf&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;cenDir&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;cenVecSize&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;output&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;cenTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;release&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;invoke-harp-daal-k-means-via-python-interface&#34;&gt;Invoke Harp-DAAL K-means via Python Interface&lt;/h2&gt;

&lt;p&gt;Harp-DAAL currently provides Python API, which interfaces
Harp-DAAL with other python written applications. By just adding several lines of python code, you
are able to deploy the original python application on Hadoop Cluster and boost the performance by
leveraging DAAL kernels.&lt;/p&gt;

&lt;p&gt;The python codes for image clustering is located at the path&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;PYTHONPATH&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt;/examples/scdemo/tutorial
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-1-run-image-clustering-on-15-scenery-dataset-with-python-scikit-learn-k-means&#34;&gt;Step.1 Run image clustering on 15 scenery dataset with Python Scikit-Learn K-means&lt;/h3&gt;

&lt;p&gt;Run the pipeline from feature extraction, training, evaluation and finally check the clusters results.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;cd&lt;/span&gt; &lt;span style=&#34;color: #960050; background-color: #1e0010&#34;&gt;$&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;{PYTHONPATH}&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;examples&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;scdemo&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;test&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;../&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;tutorial&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;/&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;run_kmeans&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;sh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/DSC-SPIDAL/harp/master/harp-daal-python/examples/scdemo/tutorial/imgcluster_runlocal.png&#34; alt=&#34;screen shot of results&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;step-2-modify-to-invokes-harp-daal&#34;&gt;Step.2 Modify to invokes Harp-DAAL&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;demo_kmeans_local.py&lt;/em&gt; is the original python codes of image clustering without Harp-DAAL.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# ############################################################################&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# call kmeans module &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# ############################################################################&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;KMeans(init&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;random&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_clusters&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;n_digits,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;max_iter&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1000&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;tol&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_init&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_jobs&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;demo_kmeans_daal.py&lt;/em&gt; replaces the above K-means module by a Harp-DAAL invocation&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# ############################################################################&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# call Harp-DAAL Kmeans module &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# ############################################################################&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;DAALKMeans(n_clusters&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;n_digits,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;max_iter&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1000&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_init&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workdir&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;/15scene-work&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;View all the modifications by&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;diff ../tutorial/demo_kmeans_local.py ../tutorial/demo_kmeans_daal.py
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/DSC-SPIDAL/harp/master/harp-daal-python/examples/scdemo/tutorial/diffcode.png&#34; alt=&#34;code diff&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;step-3-invoke-harp-daal&#34;&gt;Step.3 Invoke Harp-DAAL&lt;/h3&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;../tutorial/run_kmeans.sh daal
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-4-check-the-results-of-clustering&#34;&gt;Step.4 Check the results of clustering&lt;/h3&gt;

&lt;p&gt;Download the result files.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;# Copy a file from the running container to the host server&lt;/span&gt;
sudo docker cp &amp;lt;container-id&amp;gt;:/harp/harp-daal-python/examples/scdemo/test/local.pdf local.pdf

&lt;span style=&#34;color: #75715e&#34;&gt;# Copy a file from the server to local client&lt;/span&gt;
scp &amp;lt;username&amp;gt;@&amp;lt;server-ip&amp;gt;:&amp;lt;path-to&amp;gt;/local.pdf local.pdf
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;step-5-optional-tune-harp-daal-kmeans-parameters&#34;&gt;Step.5 (Optional) Tune Harp-DAAL-Kmeans parameters&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;daal_kmeans.py&lt;/em&gt; contains the python API to Harp-DAAL-Kmeans Java codes.
In the &lt;em&gt;&lt;strong&gt;init&lt;/strong&gt;&lt;/em&gt; function, tune the arguments (parameters) and compare the performance.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;    &lt;span style=&#34;color: #66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;__init__&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(self,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_clusters&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;max_iter&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;10&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;init&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;random&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_init&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_node&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_thread&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;8&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n_mem&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10240&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workdir&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;/kmeans-work&amp;quot;&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2&#34;&gt;):&lt;/span&gt;
        &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        n_clusters  ; set number of clusters&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        max_iter    ; set maximum iteration number&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        n_node      ; set mapper number&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        n_thread    ; set thread number in each mapper&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        init        ; set the centroid initialization method, &amp;#39;random&amp;#39; by default&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        n_init      ; set the number of runs to select the best model, 1 by default&lt;/span&gt;
&lt;span style=&#34;color: #e6db74&#34;&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;Increase iteration number &lt;em&gt;max_iter&lt;/em&gt; to check the changes in results&lt;/li&gt;
&lt;li&gt;Increase the thread number &lt;em&gt;n_thread&lt;/em&gt; to check the performance boost by multi-threading&lt;/li&gt;
&lt;li&gt;Increase the mapper number &lt;em&gt;n_node&lt;/em&gt; to check benefits from node-level parallelism.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dsc-spidal.github.io/harp/docs/harpdaal/svd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/harpdaal/svd/</guid>
      <description>

&lt;h1 id=&#34;harp-daal-singular-value-decomposition&#34;&gt;Harp - DAAL - Singular Value Decomposition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/harpdaal/SVD.png&#34; width=&#34;80%&#34; &gt;&lt;/p&gt;

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;Singular Value Decomposition is a method which seeks to reduce the rank of a data matrix, thus finding the unique vectors, features, or characteristics of the data matrix at hand. This algorithm has been used in, but is not limited to signal processing, weather prediction, hotspot detection, and recommender systems.&lt;/p&gt;

&lt;p&gt;The basic idea is to decompose the data matrix M into the following components:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/svdpng.png&#34; width=&#34;20%&#34; height=&#34;20%&#34;&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/sigma.png&#34; width=&#34;15px&#34; height=&#34;15px&#34;&gt; is a diagonal matrix holding the singular values of M. While, &lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/u.png&#34; width=&#34;15px&#34; height=&#34;15px&#34;&gt; and &lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/vt.png&#34; width=&#34;15px&#34; height=&#34;15px&#34;&gt; are orthogonal matrices which diagonalize the matrix M in some way.&lt;/p&gt;

&lt;p&gt;This package supports the implementation of Singular Value Decomposition under the Harp environment. It leverages
Intel&amp;rsquo;s DAAL computation routines to compute decomposition in a highly efficient manner and provides a wrapper
for Harp integration which uses collective communication to further optimize the algorithm.&lt;/p&gt;

&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;

&lt;h3 id=&#34;setting-up-hadoop-and-harp-daal&#34;&gt;Setting up Hadoop and Harp-daal&lt;/h3&gt;

&lt;p&gt;Details about setting up Hadoop along with Harp on the cluster can be found &lt;a href=&#34;https://dsc-spidal.github.io/harp/docs/getting-started-cluster/&#34; title=&#34;Installation&#34;&gt;here&lt;/a&gt;.
Furthermore DAAL installation and usage can be found &lt;a href=&#34;https://dsc-spidal.github.io/harp/docs/harpdaal/harpdaal/&#34; title=&#34;Daal usage&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The following commands and information are useful in understanding and writing Harp-DAAL-SVD examples.&lt;/p&gt;

&lt;h3 id=&#34;how-to-run-harp-daal-svd&#34;&gt;How to run Harp - DAAL - SVD&lt;/h3&gt;

&lt;p&gt;Easiest way to run the Harp-DAAL-SVD example is through the command line input shown below as an example (all together as one command)&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;hadoop jar harp-daal-0.1.0.jar edu.iu.daal_svd.SVDDaalLauncher -libjars &lt;span style=&#34;color: #e6db74&#34;&gt;${&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;LIBJARS&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;10000&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;20&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;2&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;64&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;185000&lt;/span&gt; /svd-P&lt;span style=&#34;color: #f8f8f2&#34;&gt;$Pts&lt;/span&gt;-C&lt;span style=&#34;color: #f8f8f2&#34;&gt;$Ced&lt;/span&gt;-D&lt;span style=&#34;color: #f8f8f2&#34;&gt;$Dim&lt;/span&gt;-N&lt;span style=&#34;color: #f8f8f2&#34;&gt;$Node&lt;/span&gt; /tmp/svd &lt;span style=&#34;color: #f8f8f2&#34;&gt;true&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&#34;explanation-of-the-arguments-required-by-harp-daal-in-the-example-input&#34;&gt;Explanation of the arguments required by Harp-DAAL in the example input&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;10000 &amp;mdash; Number of training data points&lt;/li&gt;
&lt;li&gt;20 &amp;mdash; Dimension of feature vector&lt;/li&gt;
&lt;li&gt;1 &amp;mdash; Files per mapper&lt;/li&gt;
&lt;li&gt;2 &amp;mdash; Number of nodes (mappers)&lt;/li&gt;
&lt;li&gt;64 &amp;mdash; Number of threads on each mapper (node)&lt;/li&gt;
&lt;li&gt;185000 &amp;mdash; Memory allocated to each mapper (in MB)&lt;/li&gt;
&lt;li&gt;/svd-P$Pts-C$Ced-D$Dim-N$Node &amp;mdash; workDir&lt;/li&gt;
&lt;li&gt;/tmp/svd &amp;mdash; outDir&lt;/li&gt;
&lt;li&gt;true &amp;mdash; Boolean specifying to generate data or not&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;overview-of-the-code-for-adding-routines-and-debugging&#34;&gt;Overview of the code for adding routines and debugging&lt;/h2&gt;

&lt;p&gt;A step by step introduction of main code fragments to help understand the data flow and
code structure.&lt;/p&gt;

&lt;h3 id=&#34;main-functions-in-svddaallauncher-java&#34;&gt;Main functions in SVDDaalLauncher.java&lt;/h3&gt;

&lt;hr /&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;run&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;args&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Takes and checks input given from the commandline/shell script. Initializes values like number of data points,
number of mappers, threads per mapper, memory allocated to each mapper, etcetera.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;launch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numOfDataPoints&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;vectorSize&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numPointFiles&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numMapTasks&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numThreads&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;mem&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workDir&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;localPointFilesDir&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;generateData&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Configures and launches Harp-DAAL-SVD jobs, generating data if required.&lt;/p&gt;

&lt;h3 id=&#34;main-functions-in-svddaalcollectivemapper-java&#34;&gt;Main functions in SVDDaalCollectiveMapper.java&lt;/h3&gt;

&lt;hr /&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;protected&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;mapCollective&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;KeyValReader&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;reader&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Context&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Assigns the reader to different nodes.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;runSVD&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;List&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;fileNames&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Configuration&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;conf&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Context&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This function should be visualized in three parts. In the first part it receives data and converts it into a DAAL table. It then calculuates svdStep1Local on each slave node which is the step 1 of distributed SVD algorithm.&lt;/p&gt;

&lt;p&gt;It then uses allgather to communicate data from step 1 for step 2 to be done on the master node.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;allgather&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;svd&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;sync-partial-res&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;step1LocalResultForStep2_table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;If this function is run on the master node, it receives data from each of the local nodes and computes inputForStep3FromStep2.
This is communicated to each of the local nodes using allgather.&lt;/p&gt;

&lt;p&gt;Finally, the function calculates svdStep3Local on each of the local nodes which completes the calculation of the two orthogonal matrices and extrapolates singular values as part of Singular Value Decomposition&lt;/p&gt;

&lt;p&gt;The results are printed to standard output&lt;/p&gt;

&lt;h2 id=&#34;step-1-2-and-3-references&#34;&gt;Step 1, 2, and 3 references&lt;/h2&gt;

&lt;p&gt;Step 1 on local nodes&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/step1.png&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Step 2 on master node&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/step2.png&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;&lt;br&gt;&lt;/p&gt;

&lt;p&gt;Step 3 on local nodes&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/svd/step3.png&#34; width=&#34;100%&#34; height=&#34;100%&#34;&gt;&lt;br&gt;&lt;/p&gt;

&lt;h3 id=&#34;some-nuances-of-the-code&#34;&gt;Some nuances of the code.&lt;/h3&gt;

&lt;p&gt;Serialisation of DAAL tables into HARP tables for collective communication and the deserialization
back to DAAL tables is done with the helper functions written in SVDDaalCollectiveMapper.java&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;S &amp;mdash; NumericTable containing singular values&lt;/li&gt;
&lt;li&gt;U &amp;mdash; NumericTable containing left orthogonal matrix&lt;/li&gt;
&lt;li&gt;V &amp;mdash; NumericTable containing right orthogonal matrix&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;debugging-and-testing&#34;&gt;Debugging and testing&lt;/h3&gt;

&lt;p&gt;Code is to be run on namenode and the output is generated on datanodes.
To check the std output, stderr and syslog, go to a datanode and browse to the log files
from the appropriate folder specified in core-site.xml specified during the Harp configuration.&lt;/p&gt;

&lt;p&gt;Log files are contained in latest application-xxxxx-xxx folder for the latest run and in
container-xx-xx folder inside it. The log files are distributed across different datanodes, to check each of them you have to visit different datanodes and repeat the process described
above.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://dsc-spidal.github.io/harp/docs/survey/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/survey/</guid>
      <description>

&lt;h1 id=&#34;online-survey-for-users-of-harp&#34;&gt;Online Survey for Users of Harp&lt;/h1&gt;

&lt;p&gt;We provide a brief online survey form to users. Please click &lt;a href=&#34;https://www.surveymonkey.com/r/GVVJ3HX&#34;&gt;here&lt;/a&gt; and tell us about your experience using Harp. Thank you for your time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Allgather</title>
      <link>https://dsc-spidal.github.io/harp/docs/communications/allgather/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/communications/allgather/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/3-3-1.png&#34; alt=&#34;allgather&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;allgather&lt;/code&gt; aims to first collect tables from other workers and then broadcast the collection. All workers should run it concurrently. The defination of the method is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;allgather&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;operationName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DataMap&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Workers&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;contextName&lt;/code&gt; &amp;mdash; the name of the context&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operationName&lt;/code&gt; &amp;mdash; the name of the operation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;table&lt;/code&gt; &amp;mdash; the name of the data table&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataMap&lt;/code&gt; &amp;mdash; the data map&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt; &amp;mdash; the workers&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;allgather&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;allgather&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Allreduce</title>
      <link>https://dsc-spidal.github.io/harp/docs/communications/allreduce/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/communications/allreduce/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/3-4-1.png&#34; alt=&#34;allreduce&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;allreduce&lt;/code&gt; aims to first combine tables from other workers and then broadcast the accumulated table. All workers should run it concurrently. The defination of the method is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;allreduce&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;operationName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DataMap&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Workers&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;contextName&lt;/code&gt; &amp;mdash; the name of the context&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operationName&lt;/code&gt; &amp;mdash; the name of the operation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;table&lt;/code&gt; &amp;mdash; the name of the data table&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataMap&lt;/code&gt; &amp;mdash; the data map&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt; &amp;mdash; the workers&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;allreduce&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;allreduce&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Broadcast</title>
      <link>https://dsc-spidal.github.io/harp/docs/communications/broadcast/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/communications/broadcast/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/3-1-1.png&#34; alt=&#34;broadcast&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;broadcast&lt;/code&gt; aims to share a table in one worker with others. All workers should run it concurrently. The defination of the method is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;broadcast&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;String&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;operationName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;P&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;bcastWorkerID&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;useMSTBcast&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DataMap&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Workers&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;contextName&lt;/code&gt; &amp;mdash; the name of the context&lt;/li&gt;
&lt;li&gt;&lt;code&gt;operationName&lt;/code&gt; &amp;mdash; the name of the operation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;table&lt;/code&gt; &amp;mdash; the name of the data table&lt;/li&gt;
&lt;li&gt;&lt;code&gt;bcastWorkerID&lt;/code&gt; &amp;mdash; the ID of the worker which broadcasts&lt;/li&gt;
&lt;li&gt;&lt;code&gt;useMSTBcast&lt;/code&gt; &amp;mdash; whether use MST method or not&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dataMap&lt;/code&gt; &amp;mdash; the data map&lt;/li&gt;
&lt;li&gt;&lt;code&gt;workers&lt;/code&gt; &amp;mdash; the workers&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;broadcast&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;contextName&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;chain-array-table-bcast-&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;arrTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getMasterID&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(),&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;dataMap&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;workers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Community</title>
      <link>https://dsc-spidal.github.io/harp/docs/contributors/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/contributors/community/</guid>
      <description>

&lt;h2 id=&#34;contributing-to-harp&#34;&gt;Contributing to Harp&lt;/h2&gt;

&lt;p&gt;Discussion about Harp happens on GitHub and over the mailing list.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GitHub: &lt;a href=&#34;https://github.com/DSC-SPIDAL/harp.git&#34;&gt;DSC-SPIDAL/Harp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Harp User Google Group: &lt;a href=&#34;https://groups.google.com/forum/#!forum/harp-users&#34;&gt;harp-users@googlegroups.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Community is critical to Harp. Contributions are welcome!&lt;/p&gt;

&lt;h2 id=&#34;how-can-i-contribute-to-harp&#34;&gt;How Can I Contribute to Harp?&lt;/h2&gt;

&lt;p&gt;You can first read the following pages to have a basic understanding
of Harp:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../../getting-started/&#34;&gt;Harp Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../../programming/data-interface/&#34;&gt;Data Interfaces and Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../../programming/computation-models/&#34;&gt;Computation Models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In general, contributions that fix bugs or add features (as opposed to stylistic, refactoring, or
&amp;ldquo;cleanup&amp;rdquo; changes) are preferred. Please check with &lt;a href=&#34;https://groups.google.com/forum/#!forum/harp-users&#34;&gt;mailing list&lt;/a&gt;
if your patch involves lots of changes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you have any questions or issues about troubleshooting,
you should post on &lt;a href=&#34;https://groups.google.com/forum/#!forum/harp-users&#34;&gt;mailing list&lt;/a&gt; instead
of opening GitHub issues.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;submitting-a-patch&#34;&gt;Submitting a Patch&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Read and accept the
&lt;a href=&#34;http://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache License&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Discuss your plan and design, and get to an agreement on
&lt;a href=&#34;https://groups.google.com/forum/#!forum/harp-users&#34;&gt;mailing list&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Implement proper unit tests along with your change. Verify that all tests can pass.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Submit a GitHub pull request that includes your change and test cases.
In your pull request clearly describe your change.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Complete a code review by addressing reviewers&amp;rsquo; comments.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A project committer will merge the patch to the master branch.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Data Interfaces and Types</title>
      <link>https://dsc-spidal.github.io/harp/docs/programming/data-interface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/programming/data-interface/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/2-2-1.png&#34; alt=&#34;data-abstraction&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Harp provides three levels of data structures: arrays and objects, partition, and table. Arrays and Serializable objects are the basic data structures, which include:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;ByteArray&lt;/code&gt;: an array with byte-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;ShortArray&lt;/code&gt;: an array with short-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;IntArray&lt;/code&gt;: an array with int-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;FloatArray&lt;/code&gt;: an array with float-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;LongArray&lt;/code&gt;: an array with long-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;DoubleArray&lt;/code&gt;: an array with double-type elements&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;Writable&lt;/code&gt;: serializable object&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;Partition&lt;/code&gt; is a wraper of the data structures shown above. Every partition has an ID. In collective communication, partitions from different processors with the same ID will be merged. The merge operation is defined by &lt;code&gt;PartitionCombiner&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Table&lt;/code&gt; is a container for partitions. It is a high-level data structure and the unit for collective communication.&lt;/p&gt;

&lt;h1 id=&#34;table-and-partitions&#34;&gt;Table and Partitions&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/3-1-2.png&#34; alt=&#34;table-partition&#34; /&gt;&lt;/p&gt;

&lt;p&gt;An example of how to construct a table is:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArrPlus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numPartitions&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;array&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;create&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;addPartition&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Partition&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;));&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In this example, it initiliazes a table which carries &lt;code&gt;DoubleArray&lt;/code&gt; as the primitive data type. &lt;code&gt;DoubleArrPlus&lt;/code&gt; is a &lt;code&gt;PartitionCombiner&lt;/code&gt; used to define the merging operation of two partitions.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;DoubleArrPlus&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;extends&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;PartitionCombiner&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;PartitionStatus&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;combine&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;curPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;newPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;double&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;doubles1&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;curPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size1&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;curPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;double&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;doubles2&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;newPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size2&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;newPar&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;size1&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size2&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;            &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;PartitionStatus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;COMBINE_FAILED&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
        &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size2&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2&#34;&gt;doubles1&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;doubles1&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;doubles2&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;];&lt;/span&gt;
        &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;PartitionStatus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;COMBINED&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
   &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&#34;data-abstraction&#34;&gt;Data Abstraction&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/3-1-3.png&#34; alt=&#34;data-types&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The data abstraction is shown above. &lt;code&gt;Transferable&lt;/code&gt; is ae higher interface compare to other data structures and &lt;code&gt;Simple&lt;/code&gt; is the sub-interface for all primitive data structures. Here is an example of the primitive data strucutres.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;/*&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * Copyright 2013-2016 Indiana University&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * you may not use this file except in compliance with the License.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * You may obtain a copy of the License at&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; *&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; *     http://www.apache.org/licenses/LICENSE-2.0&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; *&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * Unless required by applicable law or agreed to in writing, software&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * See the License for the specific language governing permissions and&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * limitations under the License.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; */&lt;/span&gt;

&lt;span style=&#34;color: #f92672&#34;&gt;package&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;edu.iu.harp.resource&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;java.io.DataOutput&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;java.io.IOException&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;edu.iu.harp.io.DataType&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;import&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;edu.iu.harp.resource.Array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;

&lt;span style=&#34;color: #75715e&#34;&gt;/*******************************************************&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; * IntArray class for managing int[] data.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt; ******************************************************/&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;final&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;class&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;IntArray&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;extends&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;

    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;IntArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;arr&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;start&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;super&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;arr&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;start&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #75715e&#34;&gt;/**&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * Get the number of Bytes of encoded data. One byte for storing DataType,&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * four bytes for storing the size, size*4 bytes for storing the data.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     */&lt;/span&gt;
    &lt;span style=&#34;color: #a6e22e&#34;&gt;@Override&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;getNumEnocdeBytes&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;size&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;4&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #75715e&#34;&gt;/**&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * Encode the array as DataOutput&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     */&lt;/span&gt;
    &lt;span style=&#34;color: #a6e22e&#34;&gt;@Override&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;encode&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DataOutput&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;throws&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;IOException&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;writeByte&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DataType&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;INT_ARRAY&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;start&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;writeInt&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;start&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	    &lt;span style=&#34;color: #f8f8f2&#34;&gt;out&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;writeInt&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;]);&lt;/span&gt;
	&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #75715e&#34;&gt;/**&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * Create an array. Firstly try to get an array from ResourcePool; if&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * failed, new an array.&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * @param len&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * @param approximate&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * @return&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     */&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;static&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;IntArray&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;create&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;boolean&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;approximate&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	    &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;[]&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;ints&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;ResourcePool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getIntsPool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;approximate&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	    &lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;ints&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;!=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
		&lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;IntArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;ints&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;len&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
		&lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
	    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
	&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;else&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	    &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
	&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #75715e&#34;&gt;/**&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * Release the array from the ResourcePool&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     */&lt;/span&gt;
    &lt;span style=&#34;color: #a6e22e&#34;&gt;@Override&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;release&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;ResourcePool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getIntsPool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;releaseArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;reset&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;

    &lt;span style=&#34;color: #75715e&#34;&gt;/**&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     * Free the array from the ResourcePool&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;     */&lt;/span&gt;
    &lt;span style=&#34;color: #a6e22e&#34;&gt;@Override&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;free&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
	&lt;span style=&#34;color: #f8f8f2&#34;&gt;ResourcePool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;get&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getIntsPool&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;().&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;freeArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;array&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
	&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;reset&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;

    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Developers and Contributors</title>
      <link>https://dsc-spidal.github.io/harp/docs/contributors/contributors/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/contributors/contributors/</guid>
      <description>&lt;p&gt;Judy Qiu&lt;/p&gt;

&lt;p&gt;Bingjing Zhang&lt;/p&gt;

&lt;p&gt;Bo Peng&lt;/p&gt;

&lt;p&gt;Langshi Chen&lt;/p&gt;

&lt;p&gt;Ethan Li&lt;/p&gt;

&lt;p&gt;Yiming Zou&lt;/p&gt;

&lt;p&gt;Yining Wang&lt;/p&gt;

&lt;p&gt;Abby Kaufman&lt;/p&gt;

&lt;p&gt;Mayank Jindal&lt;/p&gt;

&lt;p&gt;Prawal Gangwar&lt;/p&gt;

&lt;p&gt;Anurag Sharma&lt;/p&gt;

&lt;p&gt;Mihai Avram&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Examples Overview</title>
      <link>https://dsc-spidal.github.io/harp/docs/examples/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/examples/overview/</guid>
      <description>

&lt;p&gt;This section has six tutorials demonstrating how to implement distributed machine learning algorithms with Harp framework.&lt;/p&gt;

&lt;p&gt;Modern CPU and computation devices, such as many-core and GPU, provide powerful computing capacity but are usually challenging to deploy efficiently. To make it easier to design and implement distributed machine learning algorithms, we adopt a systematic process of parallelization with a focus on the computation models and their communication mechanisms. The tutorials provide examples of broadly used machine algorithms, including K-means, Multi-class Logistic Regression, Random Forest, Support Vector Machine, Latent Dirichlet Allocation and Neural Network, to represent the basics idea and steps for programming that port a non-trivial analysis algorithm from a sequential code into a distributed version.&lt;/p&gt;

&lt;p&gt;These examples focus on the parallelization concept and expressiveness using Harp API, rather than performance optimization. In order to explore real applications, further tuning and advanced optimizations are necessary, which have been demonstrated in to the next section of real applications.&lt;/p&gt;

&lt;p&gt;There are some general concepts that should be introduced before the tutorial starts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Input: Input data feed into the training process of the machine learning algorithm, which are also called &amp;lsquo;training data&amp;rsquo;, &amp;lsquo;data points&amp;rsquo;,&amp;lsquo;examples&amp;rsquo; or &amp;lsquo;instances&amp;rsquo;. Normally, input data are large and partitioned among the machines(nodes) in the cluster, calls &amp;lsquo;input splits&amp;rsquo;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Model: The model is the output generated when you train your machine learning algorithm with your training data-set. Here we focus on the data part.
Training: Machine learning algorithms are normally iterative computation, processing the training data and update the model in each iteration and stop when reach the stop criterion.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Prediction: Use the model learned from training data-set, and apply new data on it to get the outputs, the predictions.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Data Parallelism: Training data are partitioned among nodes and all the splits are processed in parallel. It&amp;rsquo;s essential for big data problem.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Model Parallelism: Model data are partitioned among nodes and model updates on each split are processed in parallel. It&amp;rsquo;s essential for big model problem.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The tutorial follows a similar structure, with 4 main sections:&lt;/p&gt;

&lt;h2 id=&#34;1-understanding-algorithm&#34;&gt;1. Understanding Algorithm&lt;/h2&gt;

&lt;p&gt;This part gives simple background information on the target machine learning algorithm itself. The original algorithm does not need to have parallelism in consideration.&lt;/p&gt;

&lt;h2 id=&#34;2-parallel-design&#34;&gt;2. Parallel Design&lt;/h2&gt;

&lt;p&gt;This part illustrates the process of how to analysis the original sequential algorithm and to utilize the intrinsic parallelisms to design a parallel algorithm.&lt;/p&gt;

&lt;p&gt;Under the Map-Collective programming model in Harp framework, there is a general pattern to do the parallel design for machine learning algorithms.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/4-1-1.png&#34; alt=&#34;Overview-1&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;figure-map-collective-programming-model-on-iterative-machine-learning-algorithms&#34;&gt;Figure Map-Collective Programming Model on Iterative Machine Learning Algorithms&lt;/h5&gt;

&lt;p&gt;For training data, Harp will load the local data split on each node into memory in the initialization step of training, with no disk I/O to access the training data in the future. By default, the data split mechanism support by Hadoop Mapreduce are used.&lt;/p&gt;

&lt;p&gt;For model data, Harp provides distributed dataset abstractions and collective communication and synchronization operations. Since the core computation of machine learning algorithms lies in the model update, the problems of model consistency and synchronization arise when parallelizing the core computation of model update. Harp has unique abstractions built upon collective synchronization mechanism, which is advantageous in expressiveness, efficiency and effectiveness for distributed machine learning applications.&lt;/p&gt;

&lt;p&gt;The standard steps aim to answer four questions about the model design for a distributed machine learning algorithm based on its sequential algorithm.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What is the model? What kind of data structure is applicable?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What are the characteristics of the data dependency in model update computation  can they run concurrently?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Which parallelism scheme is suitable  data parallelism or model parallelism?&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Which collective communication operation is optimal to synchronize the model?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-code-and-comments&#34;&gt;3. Code and Comments&lt;/h2&gt;

&lt;p&gt;The code snippets and comments illustrate the details of parallel implementations.&lt;/p&gt;

&lt;h2 id=&#34;4-run-demo&#34;&gt;4. Run Demo&lt;/h2&gt;

&lt;p&gt;Following the command or scripts, user can try the tutorial examples on a dataset by themselves.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harp Computation Models</title>
      <link>https://dsc-spidal.github.io/harp/docs/programming/computation-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/programming/computation-models/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/2-4-1.png&#34; alt=&#34;Inter-node Computation Model&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;computation-model-a-locking-use-the-synchronized-algorithm-and-the-latest-model-parameters&#34;&gt;Computation Model A (Locking, use the synchronized algorithm and the latest model parameters)&lt;/h2&gt;

&lt;p&gt;This Locking-based computation model guarantees each worker the exclusive access to model parameters. Once a worker trains a data item, it locks the related model parameters and prevents other workers from accessing them. When the related model parameters are updated, the worker unlocks the parameters. Thus, the model parameters used in local computation is always the latest. This computation model can be implemented through Harp event-driven APIs.&lt;/p&gt;

&lt;h2 id=&#34;computation-model-b-rotation-use-the-synchronized-algorithm-and-the-latest-model-parameters&#34;&gt;Computation Model B (Rotation, use the synchronized algorithm and the latest model parameters)&lt;/h2&gt;

&lt;p&gt;The second model is a Rotation-based computation model that rotates model parameters between workers. Each worker first takes a part of the shared model and performs training. Then, the model is shifted between the workers. Through model rotation, each model parameters are updated by one worker at a time so that the model is consistent. This computation model can be implemented with Harp rotate operation.&lt;/p&gt;

&lt;h2 id=&#34;computation-model-c-allreduce-use-the-synchronized-algorithm-and-the-stale-model-parameters&#34;&gt;Computation Model C (Allreduce, use the synchronized algorithm and the stale model parameters)&lt;/h2&gt;

&lt;p&gt;In this computation model, each process first fetches all the model parameters required by local computation. When the local computation is completed, modifications of the local model from all processes are gathered to update the model. This computation model can be implemented through either the allreduce operation for small models, the regroup+allgather operation or psuh&amp;amp;pull with big models.&lt;/p&gt;

&lt;h2 id=&#34;computation-model-d-no-sync-use-the-asynchronous-algorithm-and-the-stale-model-parameters&#34;&gt;Computation Model D (No-sync, use the asynchronous algorithm and the stale model parameters)&lt;/h2&gt;

&lt;p&gt;For the last computation model, each process independently fetches related model parameters, performs local computation, and returns model modifications. Unlike the Locking-based computation model, workers are allowed to fetch or update the same model parameters in parallel. In contrast to the Rotation and the Allreduce computation models, there is no synchronization barrier. This computation model can be implemented through Harp event-driven APIs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harp Multiclass Logistic Regression with Stochastic Gradient Descent</title>
      <link>https://dsc-spidal.github.io/harp/docs/examples/mlrsgd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/examples/mlrsgd/</guid>
      <description>

&lt;p&gt;Before going through this tutorial take a look at the &lt;a href=&#34;https://dsc-spidal.github.io/harp/docs/examples/overview/&#34;&gt;overview&lt;/a&gt; section to get an understanding of the structure of the tutorial.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/4-3-1.png&#34; width=&#34;60%&#34;  &gt;&lt;/p&gt;

&lt;p&gt;Definitions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;N&lt;/code&gt; is the number of data points&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;/code&gt; is the number of labels&lt;/li&gt;
&lt;li&gt;&lt;code&gt;M&lt;/code&gt; is the number of features&lt;/li&gt;
&lt;li&gt;&lt;code&gt;W&lt;/code&gt; is the &lt;code&gt;T*M&lt;/code&gt; weight matrix&lt;/li&gt;
&lt;li&gt;&lt;code&gt;K&lt;/code&gt; is the number of iteration&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;Multiclass logistic regression (MLR)&lt;/code&gt; is a classification method that generalizes logistic regression to multiclass problems, i.e. with more than two possible discrete outcomes. It is a model that is used to predict the probabilities of the different possible outcomes of a categorically distributed dependent variable, given a set of independent variables.&lt;/p&gt;

&lt;p&gt;The process of the MLR algorithm is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Use the weight &lt;code&gt;W&lt;/code&gt; to predict the label of current data point.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Compare the output and the answer.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Use SGD to approximate &lt;code&gt;W&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Repeat step 1 to 3 with each label and their weights.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code&gt;Stochastic gradient descent (SGD)&lt;/code&gt; is a stochastic approximation of the gradient descent optimization method for minimizing an objective function that is written as the sum of differentiable functions. In other words, SGD tries to find minimums or maximums by iteration. As the algorithm sweeps through the training set, it performs the update for each training example. Several passes can be made over the training set until the algorithm converges.&lt;/p&gt;

&lt;p&gt;The SGD algorithm can be described as following:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Randomly assign the weight &lt;code&gt;W&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Shuffle &lt;code&gt;N&lt;/code&gt; data points.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Go through &lt;code&gt;N&lt;/code&gt; data points and do gradient descent.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Repeat step 2 and 3 &lt;code&gt;K&lt;/code&gt; times.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;parallel-design&#34;&gt;PARALLEL DESIGN&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What are the models? What kind of data structure is applicable?&lt;/p&gt;

&lt;p&gt;The weight vectors for classes are models. Because an ovr(one-versus-rest) approach is adopted, each weight vector is independent. It has a matrix structure.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What are the characteristics of the data dependency in model update computation? Can updates run concurrently?&lt;/p&gt;

&lt;p&gt;Model update computation here is the SGD update, in which for each data point it should update the model directly. Because of the ovr strategy, each row in the model matrix is independent, and can be updated in parallel.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Which kind of parallelism scheme is suitable, data parallelism or model parallelism?&lt;/p&gt;

&lt;p&gt;Data parallelism can be used, i.e., calculating different data points in parallel.&lt;/p&gt;

&lt;p&gt;Because the updates can run concurrently, model parallelism is a nature solution.  Each node gets one partition of the model, which updates in parallel. And furthermore, thread level parallelism can also follow this model parallelism pattern, that each thread takes a subset of partition and updates in parallel independently.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Which collective communication operation is suitable to synchronize the model?&lt;/p&gt;

&lt;p&gt;DynamicScheduler can be used for thread-level parallelism, and Rotate can be used in the inter-node model synchronization.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;dataflow&#34;&gt;DATAFLOW&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/4-3-2.png&#34; alt=&#34;dataflow&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;step-0-data-preprocessing&#34;&gt;Step 0 &amp;mdash; Data preprocessing&lt;/h2&gt;

&lt;p&gt;Harp MLR will use the data in the vector format. Each vector in a file is represented by the format &lt;code&gt;&amp;lt;did&amp;gt; [&amp;lt;fid&amp;gt;:&amp;lt;weight&amp;gt;]&lt;/code&gt;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;did&amp;gt;&lt;/code&gt; is an unique document id&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;fid&amp;gt;&lt;/code&gt; is a positive feature id&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;weight&amp;gt;&lt;/code&gt; is the number feature value within document weight&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After preprocessing, push the data set into HDFS by the following commands.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;hdfs dfs -mkdir /input
hdfs dfs -put input_data/* /input
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;step-1-initialize&#34;&gt;Step 1 &amp;mdash; Initialize&lt;/h2&gt;

&lt;p&gt;For Harp MLR, we will use dynamic scheduling as mentioned above. Before we set up the dynamic scheduler, we need to initialize the weight matrix &lt;code&gt;W&lt;/code&gt;, which will be partitioned into &lt;code&gt;T&lt;/code&gt; parts representing to &lt;code&gt;T&lt;/code&gt; labels which means that each label belongs to one partition and is treated as an independent task.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;initTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArrPlus&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;topics&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;size&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;addPartition&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Partition&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;create&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;TERM&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;false&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)));&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;After that, we can initialize the dynamic scheduler. Each thread will be treated as a worker and will be added into the scheduler. The only thing that needs to be done is that tasks have to be submitted during the computation.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;private&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;initThread&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDthread&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;LinkedList&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numThread&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDthread&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;add&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDtask&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;alpha&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;data&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;topics&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;qrels&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;));&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DynamicScheduler&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;GDthread&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;step-2-mapper-communication&#34;&gt;Step 2 &amp;mdash; Mapper communication&lt;/h2&gt;

&lt;p&gt;In this main process, we use &lt;code&gt;regroup&lt;/code&gt; to distribute the partitions to the workers first. The workers will get almost the same number of partitions. Then we start the scheduler. Each time we submit one partition to each thread in the scheduler, the threads will all use SGD to approximate &lt;code&gt;W&lt;/code&gt; with each label. After the workers finish once with their own partitions, we will use &lt;code&gt;rotate&lt;/code&gt; operation to swap the partitions among the workers. After all the processes finish, each worker should use its own data training the whole partition &lt;code&gt;K&lt;/code&gt; times, where &lt;code&gt;K&lt;/code&gt; is the number of iterations. &lt;code&gt;allgather&lt;/code&gt; operation collects all partitions in each worker, combines the partitions, and shares the outcome with all workers. Finally, the Master worker outputs the weight matrix &lt;code&gt;W&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;protected&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;void&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;mapCollective&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;KeyValReader&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;reader&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Context&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;throws&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;IOException&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;InterruptedException&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;LoadAll&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;reader&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;initTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;initThread&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;

    &lt;span style=&#34;color: #f8f8f2&#34;&gt;regroup&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;MLR&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;regroup_wTable&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;new&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Partitioner&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;getNumWorkers&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;()));&lt;/span&gt;

    &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;start&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;        
    &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;iter&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #ae81ff&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;iter&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;ITER&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;*&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numMapTask&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;iter&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;++)&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;for&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;Partition&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;par&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;:&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getPartitions&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;())&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;submit&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;par&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
        &lt;span style=&#34;color: #66d9ef&#34;&gt;while&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;hasOutput&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;())&lt;/span&gt;
            &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;waitForOutput&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
            
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;rotate&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;MLR&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;rotate_&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;iter&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;null&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

        &lt;span style=&#34;color: #f8f8f2&#34;&gt;context&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;progress&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
    &lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;GDsch&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;stop&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
        
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;allgather&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;MLR&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;allgather_wTable&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

    &lt;span style=&#34;color: #66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;isMaster&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;())&lt;/span&gt;
        &lt;span style=&#34;color: #f8f8f2&#34;&gt;Util&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;outputData&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;outputPath&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;topics&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;conf&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;wTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;release&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;();&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;usage&#34;&gt;USAGE&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ hadoop jar contrib-0.1.0.jar edu.iu.mlr.MLRMapCollective &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;alpha&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;number of iteration&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;number of features&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;number of workers&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;number of threads&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;topic file path&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;qrel file path&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;input path in HDFS&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;[&lt;/span&gt;output path in HDFS&lt;span style=&#34;color: #f92672&#34;&gt;]&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;#e.g. hadoop jar contrib-0.1.0.jar edu.iu.mlr.MLRMapCollective 1.0 100 47236 2 16 /rcv1v2/rcv1.topics.txt /rcv1v2/rcv1-v2.topics.qrels /input /output&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The output should be the weight matrix &lt;code&gt;W&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harp Neural Network</title>
      <link>https://dsc-spidal.github.io/harp/docs/examples/nn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/examples/nn/</guid>
      <description>

&lt;p&gt;Before going through this tutorial take a look at the &lt;a href=&#34;https://dsc-spidal.github.io/harp/docs/examples/overview/&#34;&gt;overview&lt;/a&gt; section.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/nn.png&#34; width=&#34;60%&#34;  &gt;&lt;/p&gt;

&lt;p&gt;Neural networks are a set of algorithms, which is based on a large of neural units. Each neural unit is connected with many others, and forms a network structure. Computation happens in the neural unit, which combines all the inputs with a set of coefficients, or weights, and gives an output by an activation function. A layer is a group of neural units, that each layers output is the subsequent layers input. A learning algorithm tries to learn the weights from data, and then the network can be used to recognize patterns.&lt;/p&gt;

&lt;p&gt;Here, we give a simple tutorial on how to parallel a standard implementation of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Backpropagation&#34;&gt;BP algorithm&lt;/a&gt; for a feed-forward network.&lt;/p&gt;

&lt;h2 id=&#34;parallel-design&#34;&gt;PARALLEL DESIGN&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;What is the model? What kind of data structure is applicable?&lt;/p&gt;

&lt;p&gt;Weights matrices, including the biases for each node, between each adjacent layers are the model in neural network. It is a vector of double matrix.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;What are the characteristics of the data dependency in model update computation? Can updates run concurrently?&lt;/p&gt;

&lt;p&gt;In the core model update computation in BP training algorithm, each data point, or a minibatch, should access all the model, compute gradients and update model layer by layer from the output layer back to the input layer.&lt;/p&gt;

&lt;p&gt;The nodes in the same layer can be updated in parallel without conflicts, but there are dependency between the layers. But generally, it is not easy to utilize these network structure related parallelism.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Which kind of parallelism scheme is suitable, data parallelism or model parallelism?&lt;/p&gt;

&lt;p&gt;Data parallelism can be used, i.e., calculating different data points in parallel.&lt;/p&gt;

&lt;p&gt;No model parallelism, each node get one replica of the whole model, which updates locally in parallel, and then synchronizes and averages when local computation all finish.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;which collective communication operation is suitable to synchronize the model?&lt;/p&gt;

&lt;p&gt;Synchronize replicas of the model by allreduce is an simple solution.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;dataflow&#34;&gt;DATAFLOW&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/nn-dataflow.png&#34; width=&#34;60%&#34;  &gt;&lt;/p&gt;

&lt;h2 id=&#34;step-1-set-table&#34;&gt;Step 1 &amp;mdash; Set Table&lt;/h2&gt;

&lt;p&gt;The data format wrapper code is in charge of the conversion between the native DoubleMatrix and Harp Table.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;public&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #a6e22e&#34;&gt;train&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleMatrix&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;X&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleMatrix&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Y&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;localWeightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;mini_epochs&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;int&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numMapTasks&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;double&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;lambda&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;)&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;throws&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;IOException&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;{&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;Vector&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleMatrix&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;weightMatrix&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;reshapeTableToList&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;localWeightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
    &lt;span style=&#34;color: #f8f8f2&#34;&gt;setTheta&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;weightMatrix&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

    &lt;span style=&#34;color: #f8f8f2&#34;&gt;trainBP&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;X&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Y&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;lambda&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;mini_epochs&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;true&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

    &lt;span style=&#34;color: #f8f8f2&#34;&gt;Table&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;DoubleArray&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;newWeightTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;reshapeListToTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;this&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;getTheta&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;());&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;newWeightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;;&lt;/span&gt;
&lt;span style=&#34;color: #f92672&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;step-2-communication&#34;&gt;Step 2 &amp;mdash;Communication&lt;/h2&gt;

&lt;p&gt;The code snippet for the core part of computation in the iterative training. There  are only a few lines of differences between the harp distributed version and the original sequential version.&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #75715e&#34;&gt;// Calculate the new weights &lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;// argument data type conversion and call the train() in the underlie library&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;weightTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;localNN&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;train&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;X&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;Y&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;weightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;n&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numMapTasks&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;lambda&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

&lt;span style=&#34;color: #75715e&#34;&gt;// reduce and broadcast&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;allreduce&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;main&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;allreduce&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;+&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;i&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;weightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;

&lt;span style=&#34;color: #75715e&#34;&gt;// Average the weight table by the numMapTasks&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;weightTable&lt;/span&gt; &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;localNN&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;.&lt;/span&gt;&lt;span style=&#34;color: #a6e22e&#34;&gt;modelAveraging&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;weightTable&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;,&lt;/span&gt; &lt;span style=&#34;color: #f8f8f2&#34;&gt;numMapTasks&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;);&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h2 id=&#34;data&#34;&gt;DATA&lt;/h2&gt;

&lt;p&gt;The MNIST dataset is used in this tutorial. Refer the &lt;a href=&#34;https://github.com/DSC-SPIDAL/harp/tree/master/data/tutorial/mnist&#34;&gt;dataset script&lt;/a&gt; for more details.&lt;/p&gt;

&lt;h2 id=&#34;usage&#34;&gt;USAGE&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;$ hadoop jar contrib-0.1.0.jar edu.iu.NN.NNMapCollective
Usage: NNMapCollective &amp;lt;number of map tasks&amp;gt; &amp;lt;epochs&amp;gt; &amp;lt;syncIterNum&amp;gt; &amp;lt;hiddenLayers&amp;gt; &amp;lt;minibatchsize&amp;gt; &amp;lt;lambda&amp;gt; &amp;lt;workDir&amp;gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# hadoop jar contrib-0.1.0.jar edu.iu.NN.NNMapCollective 2 20 5 100,32 2000 0 /nn&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This command run harp neuralnetwork training on the input dataset under /nn, with 2 mappers. Training process goes through 20 times of the training dataset, averages the model every 5 iteration for each minibatch. The minibatch size is 2000, lambda is default value 0.689. There are 2 hidden layers, with 100 and 32 nodes each. Finally, it outputs the accuracy on the training set into the hadoop log.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Harp Overview</title>
      <link>https://dsc-spidal.github.io/harp/docs/programming/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dsc-spidal.github.io/harp/docs/programming/overview/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://dsc-spidal.github.io/harp/img/harp-overview.png&#34; alt=&#34;Overview-0&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;big-model-problems-and-the-limitation-of-existing-tools&#34;&gt;Big Model Problems and The Limitation of Existing Tools:&lt;/h2&gt;

&lt;p&gt;Data analytics is undergoing a revolution in many scientific domains. Machine learning becomes a popular method for analytics for which it allows computers to learn from the existing data and make predictions based off it. They have been widely used in computer vision, text mining, advertising, recommender systems, network analysis and genetics. Unfortunately, analyzing such huge data usually exceeds the capability of a single or even a few machines owing to the incredible volume of data available, and thus requires algorithm parallelization at an unprecedented scale. Scaling up these algorithms is challenging because of their prohibitive computation cost, not only the need to process enormous training data in iterations, but also the requirement to synchronize big model in rounds for algorithm convergence. The problem is simply referred as &amp;ldquo;the big model problem of big data machine learning&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Many machine learning algorithms were implemented in MapReduce. However, these implementations suffer from repeated input data loading from the distributed file systems and slow disk-based intermediate data synchronization in the shuffling phase. This motivates the design of iterative MapReduce tools which utilize memory for data caching and communication and thus drastically improve the performance of large-scale data processing. Later big data tools have expanded rapidly and form an open-source software stack. Their programming models are not limited to MapReduce and iterative MapReduce. In graph processing tools, input data are abstracted as a graph and processed in iterations, while intermediate data per iteration are expressed as messages transmitted between vertices. In parameter servers, model parameters are stored in a set of server machines and they can be retrieved asynchronously in parallel processing.&lt;/p&gt;

&lt;p&gt;While in contemporary tools performance is improved with in-memory caching, observations show that the parallelization of these iterative applications still suffers from two issues. To simplify the programming process, many tools design tries to fix the parallel execution flow and developers are only required to fill the bodies of user functions. However this results in limited support of the synchronization patterns. The parallelization performance suffers from performance inefficiency due to in-proper usage of synchronization patterns. To avoid this issue, some work turn to use MPI to develop machine learning applications. However, these applications developed achieve high performance but fall into the complicated code bases since MPI only provides basic communication operations.&lt;/p&gt;

&lt;h2 id=&#34;harp-highlights&#34;&gt;Harp Highlights:&lt;/h2&gt;

&lt;p&gt;To solve the problems mentioned above, the Harps approach is to use collective communication techniques to improve the performance of model synchronization in parallel machine learning. Therefore a MapCollective programming model is extended from the original MapReduce programming model. Similar to the MapReduce model, the MapCollective model still read key-value pairs as inputs. However, instead of using the shuffling phase, Harp uses optimized collective communication operations for data movement and provide high-level interfaces with partitioned distributed dataset abstractions for various synchronization patterns in iterative machine learning computation. These enhancements are designed as plug-ins to Hadoop so Harp can enrich the whole big data software stack.&lt;/p&gt;

&lt;p&gt;With the Harp framework, the project focuses on building a machine learning library with the programming interfaces provided. Our research shows parallel machine learning applications can be categorized to four types of computation models. The classification of the computation models is based on the synchronization patterns and the effectiveness of the model parameter update. These computation models are mapped to the Harp programming interfaces to simplify the programming of machine learning applications. In sum, the Harps contribution includes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Harp provides a collective communication library as a Hadoop plug-in and a set of Map-Collective programming interfaces to develop iterative machine learning applications with various synchronization patterns.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Four parallel computation models are categorized to characterize the parallelization of machine learning applications. Allreduce and Rotation based Computation models can be mapped to the Harp collective communication interfaces in order to simplify the implementation of parallel machine learning applications.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A collection of machine learning algorithms are implemented, including K-means Clustering, Multiclass Logistic Regression (MLR), Support Vector Machine (SVM), Latent Dirichlet Allocation (LDA) and Matrix Factorization (MF).  Our experiment results of LDA implementations reveal that the &amp;ldquo;Rotation&amp;rdquo; based computation model is faster than the Allreduce type computation model. Now three algorithms are built on top of model rotation: Collapsed Gibbs Sampling (CGS) for LDA, Stochastic Gradient Descent (SGD) and Cyclic Coordinate Descent (CCD) for MF. The performance results on an Intel Haswell cluster show that our solution achieves faster model convergence speed and higher scalability compared with other related work.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>